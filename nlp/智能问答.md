https://mp.weixin.qq.com/s?__biz=MjM5MDI3MjA5MQ==&mid=2697267385&idx=1&sn=c95b23266f53de3210ed663ebfdca225&chksm=8376f78db4017e9bd1ae349b749fe3d6173e07058a7cc698044bd57a598392f78007233c09b8&mpshare=1&scene=1&srcid=0808pBOnWHDyHeCY4WsUO82x#rd

## 
1. 传统做法
- 根据关键词检索或BM25等算法计算相关性排序
- 缺点：需要维护大量的同义词典库和匹配规则

2. 浅层主题模型
- 潜在语义分析技术（Latent Semantic Analysis，LSA[1,2]）
- PLSA（Probabilistic Latent Semantic Analysis）[3]
- LDA（LatentDirichlet Allocation）[4]
- 对文本的语义表示形式简洁，较好地弥补了传统词汇匹配方法的不足。不过从效果上来看，这些技术都无法完全替代基于字词的匹配技术。

3. 深度学习
- Word2vec[5]
- 句子级别
    - Microsoft Research 提出的 DSSM 模型（Deep Structured Semantic Model）[6]
    - 华为实验室也提出了一些新的神经网络匹配模型变体[7,8,9]
    - 中科院等研究机构也提出了诸如多视角循环神经网络匹配模型（MV-LSTM）[10]、基于矩阵匹配的的层次化匹配模型 MatchPyramid[11]等更加精致的神经网络文本匹配模型

## 排序
- point-wise, pair-wise和list-wise


[1] DennisS, Landauer T, Kintsch W, et al. Introduction to latent semanticanalysis[C]//Slides from the tutorial given at the 25th Annual Meeting of theCognitive Science Society, Boston. 2003.

[2] DeerwesterS, Dumais S T, Furnas G W, et al. Indexing by latent semantic analysis[J].Journal of the American society for information science, 1990, 41(6): 391-407.

[3] HofmannT. Unsupervised learning by probabilistic latent semantic analysis[J]. Machinelearning, 2001, 42(1-2): 177-196.

[4] BleiD M, Ng A Y, Jordan M I. Latent dirichlet allocation[J]. Journal of machineLearning research, 2003, 3(Jan): 993-1022.

[5] MikolovT, Chen K, Corrado G, et al. Efficient estimation of word representations invector space[J]. arXiv preprint arXiv:1301.3781, 2013.

[6] HuangP S, He X, Gao J, et al. Learning deep structured semantic models for websearch using clickthrough data[C]//Proceedings of the 22nd ACM internationalconference on Conference on information & knowledge management. ACM, 2013:2333-2338.

[7] LuZ, Li H. A deep architecture for matching short texts[C]//Advances in NeuralInformation Processing Systems. 2013: 1367-1375.

[8] JiZ, Lu Z, Li H. An information retrieval approach to short text conversation[J].arXiv preprint arXiv:1408.6988, 2014.

[9] HuB, Lu Z, Li H, et al. Convolutional neural network architectures for matchingnatural language sentences[C]//Advances in neural information processingsystems. 2014: 2042-2050.

[10]Wan,Shengxian, Yanyan Lan, Jiafeng Guo, Jun Xu, Liang Pang, and XueqiCheng."A Deep Architecture for Semantic Matching with MultiplePositionalSentence Representations." In AAAI, pp. 2835-2841. 2016.

[11]Pang,Liang, Yanyan Lan, Jiafeng Guo, Jun Xu, Shengxian Wan, and XueqiCheng."Text Matching as Image Recognition." In AAAI, pp. 2793-2799.2016.s

[12] FengM, Xiang B, Glass M R, et al. Applying deep learning to answer selection: Astudy and an open task[J]. arXiv preprint arXiv:1508.01585, 2015.

[13] LaiS, Xu L, Liu K, et al. Recurrent Convolutional Neural Networks for TextClassification[C]//AAAI. 2015, 333: 2267-2273.

[14] SantosC, Tan M, Xiang B, et al. Attentive pooling networks[J]. arXiv preprintarXiv:1602.03609, 2016.

[15] KimY. Convolutional neural networks for sentence classification[J]. arXiv preprintarXiv:1408.5882, 2014.

[16] YoungS, Gašić M,Thomson B, et al. Pomdp-based statistical spoken dialog systems: A review[J].Proceedings of the IEEE, 2013, 101(5): 1160-1179.

[17] LangleyP, Meadows B, Gabaldon A, et al. Abductive understanding of dialogues aboutjoint activities[J]. Interaction Studies, 2014, 15(3): 426-454.

[18] SerbanI V, Sordoni A, Bengio Y, et al. Building End-To-End Dialogue Systems UsingGenerative Hierarchical Neural Network Models[C]//AAAI. 2016, 16: 3776-3784.

[19] SordoniA, Galley M, Auli M, et al. A neural network approach to context-sensitivegeneration of conversational responses[J]. arXiv preprint arXiv:1506.06714,2015.