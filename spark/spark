spark

简介
- 专为大规模数据处理而设计的快速通用的计算引擎，是UC Bererkeley开源设计的，由scala开发。
- 对比Hadoop MapReduce
  更适用于以下场景：迭代任务（如梯度下降计算，map reduce要从硬盘进行读写，spark从内存进行读写）
                  交互式分析（hive延时大，因为要起一个单独的map reduce job，并且要从硬盘进行读写,Presto也有相应的问题）
  代码简洁                
- speed：100x faster -- DAG scheduler,query optimizer,physical execution engine
- API丰富:java,scala,python,r,sql  
- 通用性：spark sql,spark streaming,mllib,graphx
- runs everywhere：hadoop，standalone...  

- spark运行架构 https://cloud.tencent.com/developer/article/1004889
	- stage,task,worker,partition
	- executor,cores
Master-Slave	
Driver向Master申请资源；Worker负责监控自己节点的内存和CPU情况，并向Master汇报；Master给Worker分配资源，时刻知道Worker的资源状况
集群管理器：mesos，yarn,standalone
一个物理节点可以有一个或多个worker,一个worker可以有一个或多个executor，一个executor可以有多个cpu core
一个partition对应一个task,cores代表可以同时并行的task数
shuffle：将分布在集群中多个节点上的同一个key，拉取到同一个节点上，进行聚合或join等操作（比如reduceByKey、join、distinct、repartition等算子）。代价很大：重新进行数据分区，数据传输

- yarn-cluster，yarn-client
yarn-cluster：适用于生产环境
yarn-client：适用于交互和调试

- RDD（弹性分布式数据集）
falut tolerance：任何partition丢失了，都可以从头恢复
记录生成rdd的计算过程
生成rdd： parallelizing an existing collection in your driver program, or referencing a dataset in an external storage system, such as a shared filesystem, HDFS, HBase, or any data source offering a Hadoop InputFormat, or transform from other rdd 
惰性计算:action触发
transform操作（create a new dataset）: map,filter,flatMap,mapPartitions,sample,union,join,groupByKey,distinct,
action操作(return a value to the driver program):reduce,collect,count,foreach
shuffle操作（re-distributing data so that it’s grouped differently across partitions）：repartition，groupByKey，join
cache、persist：reuse，storage level
printing elements of RDD：rddforeach(println)---print to the executor's stdout,not the driver's stdout;
                          rdd.collect().foreach(println)--print to the driver's stdout

- 函数传递
1. 匿名函数：当函数代码比较短
2. 单例对象中的静态方法

- 闭包
代码+用到的局部变量

- 共享变量
广播变量
累加器：闭包（类似foreach）修改全局变量的操作结果不能保证，要使用累积器
       https://blog.csdn.net/u013468917/article/details/70617085

- DAG图
spark有两类task： shuffleMapTask ---- 输出shuffle所需数据
                 resultTask ---- 输出result
stage划分：从后往前推，遇到宽依赖就断开，划分为一个stage，遇到窄依赖就将这个RDD加入该stage中                 

- 宽依赖，窄依赖
窄依赖：父RDD的每个分区只被子RDD的一个分区所使用：map、filter、union、join with inputs co-partitioned(父RDD hash-partitioned),mapPartitions,mapValues
宽依赖：父RDD的每个分区只被子RDD的多个分区所使用：groupByKey、join with inputs not co-partitioned（父RDD 不是 hash-partitioned)
窄依赖对优化有利：
  宽依赖对应shuffle操作，开销大
  当RDD分区丢失时，窄依赖只需要计算和子RDD分区对应的父RDD分区即可，宽依赖要计算多个父RDD分区，甚至是全部分区

- 集群部署

- Dataset,DataFrame,RDD 比较
相同：
	- 惰性机制
	- 根据内存情况自动缓存运算？
	- partition概念，如mappartition对每一个分区进行操作，数据量小，而且可以将运算结果拿出来，map中对外面变量的操作是无效的
	- 有共同的方法，如filter、排序等
不同：
    - RDD:不支持spark sql，支持spark mllib
    - DataFrame、Dataset：支持spark ml、spark sql
DataFrame VS Dataset
	DataFrame：Dataset[Row]，每一行的类型是Row
	Dataset访问列中的某个字段方便
转化
	DataFrame/Dataset 转RDD df.rdd
	RDD转DataFrame：import spark.implicits._
					val testDF = rdd.map {line=>
					      (line._1,line._2)
					    }.toDF("col1","col2")
	RDD转DataSet：import spark.implicits._
					case class Coltest(col1:String,col2:Int)extends Serializable //定义字段名和类型
					val testDS = rdd.map {line=>
					      Coltest(line._1,line._2)
					    }.toDS
	Dataset转DataFrame：   import spark.implicits._
							val testDF = testDS.toDF	
	DataFrame转Dataset：	case class Coltest(col1:String,col2:Int)extends Serializable //定义字段名和类型
						val testDS = testDF.as[Coltest]					   			    

- spark2.0

- spark sql
  数据读取及处理

- mllib
  pipeline
  特征处理
  建模

- 提交任务
  spark-submit
  先定义SparkContext，SparkConf ： 表明和集群的连接方式 （spark-shell模式下已经定义好了）

- spark优化
https://tech.meituan.com/spark-tuning-basic.html
https://tech.meituan.com/spark-tuning-pro.html
  - 2-4 partitions for each CPU
  - 尽量避免使用shuffle类算子：shuffle过程中，各个节点上的相同key都会先写入本地磁盘，然后其他节点需要通过网络传输拉取各个节点上的磁盘文件中的相同key。而且相同key都拉取到同一个节点进行聚合操作时，还有可能会因为一个节点上处理的key过多，导致内存不够存放，进而溢写到磁盘文件中。因此在shuffle过程中，可能会发生大量的磁盘文件读写的IO操作，以及数据的网络传输操作。磁盘IO和网络数据传输也是shuffle性能较差的主要原因。尽量使用map等非shuffle算子
  - join减少shuffle:1. reaprtition(窄依赖，避免shuffle)： hash-partitioned, rdd.partitionBy(new HashPartitioner(num)).persist()
                          					            dataframe.repartition(num，colname to join) -- The resulting Dataset is hash partitioned.This is the same operation as   "DISTRIBUTE BY" in SQL (Hive QL). 
         2. Broadcast与map进行join操作
             // 传统的join操作会导致shuffle操作。
			// 因为两个RDD中，相同的key都需要通过网络拉取到一个节点上，由一个task进行join操作。
			val rdd3 = rdd1.join(rdd2)

			// Broadcast+map的join操作，不会导致shuffle操作。
			// 使用Broadcast将一个数据量较小的RDD作为广播变量。
			val rdd2Data = rdd2.collect()
			val rdd2DataBroadcast = sc.broadcast(rdd2Data)

			// 在rdd1.map算子中，可以从rdd2DataBroadcast中，获取rdd2的所有数据。
			// 然后进行遍历，如果发现rdd2中某条数据的key与rdd1的当前数据的key是相同的，那么就判定可以进行join。
			// 此时就可以根据自己需要的方式，将rdd1当前数据与rdd2中可以连接的数据，拼接在一起（String或Tuple）。
			val rdd3 = rdd1.map(rdd2DataBroadcast...)

			// 注意，以上操作，建议仅仅在rdd2的数据量比较少（比如几百M，或者一两G）的情况下使用。
			// 因为每个Executor的内存中，都会驻留一份rdd2的全量数据。
  - 多次使用的RDD进行持久化
  - 使用filter之后进行coalesce
  - 广播大变量
- scala语法
  强类型
  “_”的用法

  
  
  参考资料
-- spark官网文档
-- spark github 源码 
-- scala语法
-- 三篇论文
-- 吴磊的ppt、wsy的ppt